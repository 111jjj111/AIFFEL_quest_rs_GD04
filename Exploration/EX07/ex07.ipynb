{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2763a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting koeda\n",
      "  Downloading koeda-0.0.4-py3-none-any.whl (566 kB)\n",
      "     |████████████████████████████████| 566 kB 7.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: konlpy>=0.5.2 in /opt/conda/lib/python3.9/site-packages (from koeda) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.9/site-packages (from koeda) (1.21.4)\n",
      "Requirement already satisfied: tweepy==3.10.0 in /opt/conda/lib/python3.9/site-packages (from koeda) (3.10.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy==3.10.0->koeda) (2.26.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy==3.10.0->koeda) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tweepy==3.10.0->koeda) (1.3.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from konlpy>=0.5.2->koeda) (4.6.3)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from konlpy>=0.5.2->koeda) (0.4.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.9/site-packages (from konlpy>=0.5.2->koeda) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy>=0.5.2->koeda) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy==3.10.0->koeda) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2.0.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (1.7.1)\n",
      "Installing collected packages: koeda\n",
      "Successfully installed koeda-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install koeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "627cbf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea5acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "        \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        # position : padded input size, 행의 크기\n",
    "        # d_model : 임베딩 차원, 열의 크기\n",
    "        # angle shape : (1, d_model)\n",
    "        # position shape : (position, 1)\n",
    "        # return shape : (position, d_model)\n",
    "        angles = 1 / tf.pow(10000, (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            # position * angle을 위해서 newaxis를 작성\n",
    "            position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model\n",
    "        )\n",
    "        \n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        # [2, position, d_model*0.5]\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        # [position, d_model*0.5, 2]\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "        # [position, d_model], sin과 cosine이 교차\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "        # [1, position, d_model]\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        position = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encoding[:, :position, :]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc42571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query, key, value : (batch, n_heads, n_token, depth)\n",
    "    \n",
    "    # Q·K^T 연산 (키 텐서의 마지막 두 차원 전치)\n",
    "    # (batch, n_heads, n_token, depth) × (batch, n_heads, depth, n_token)\n",
    "    # → (batch, n_heads, n_token, n_token)\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # depth : d_model // num_heads (멀티헤드 일 때)\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "        \n",
    "    # axis = -1 : 각 query에 대해 key들 전체에 softmax를 적용\n",
    "    # logit의 각 행마다 softmax를 적용함.\n",
    "    # 모든 행의 합은 각각 1\n",
    "    # shape : (batch, n_heads, n_token, n_token)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    # return shape : (batch, n_heads, n_token, depth)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58360f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        # shape : (batch, n_token, d_model) \n",
    "        # -> (batch, n_token, num_heads, depth)\n",
    "        # -> (batch, num_heads, n_token, depth)\n",
    "        inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "        # shape : (batch, n_heads, n_token, depth)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # -> (batch, n_token, n_heads, depth)\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                     (batch_size, -1, self.d_model))\n",
    "        \n",
    "        outputs = self.dense(concat_attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b616d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    # tf.math.equal(x, y) : x와 y의 값이 같으면 True, 아니면 False\n",
    "    # shape : (batch, 1, 1, seq_length)\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b22be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \"\"\"\n",
    "    tf.linalg.band_part(\n",
    "    input,      # 입력 텐서 (2D 이상의 행렬)\n",
    "    num_lower,  # 유지할 하부 대각선(subdiagonal) 수 (음수: 전체 하부 삼각행렬 유지)\n",
    "    num_upper,  # 유지할 상부 대각선(superdiagonal) 수 (음수: 전체 상부 삼각행렬 유지)\n",
    "    name=None\n",
    "    ) : 입력 텐서의 대각선 주변 밴드 영역을 유지하고 나머지를 0으로 설정\n",
    "    \n",
    "    num_lower=0, num_upper=-1: 상부 삼각행렬 추출.\n",
    "    num_lower=-1, num_upper=0: 하부 삼각행렬 추출.\n",
    "    num_lower=0, num_upper=0: 대각선 요소만 유지.\n",
    "    \"\"\"\n",
    "    # 하부 삼각행렬이 0, 나머지는 1이 되도록\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    # 두 패딩 중 하나라도 1이면 마스크가 적용됨.\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e4a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    # input으로 토큰 1개씩 입력받나?\n",
    "    # input의 시퀀스의 길이가 가변적임을 의미\n",
    "    # input shape : (batch, seq_len, d_model)\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    \n",
    "    # mask는 shape이 (batch, 1, 1, seq_len)이었는데, input이 이게 맞나?\n",
    "    # 위와 같이 시퀀스의 길이가 가변적이기 때문에 아래와 같이 작성됨.\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "    \n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    # LayerNormalization에는 왜 inputs + attention을 하지?\n",
    "    # Residual connection(잔차 연결), 입력과 출력을 더하여 학습을 안정화시켰다.\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    # 여기서는 왜 attention + outputs를 하지?\n",
    "    # Residual connection, 어텐션블럭의 출력과 feed-foward블럭의 출력을 더했다.\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention+outputs)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9eba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, max_legnth, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    \n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    # embedding에 root(d_model)을 곱하는 이유는?\n",
    "    # transformer 원 논문에서 제안된 트릭, 단어 임베딩과 위치 임베딩의 스케일을 맞추기 위함.\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # positional encoding의 position input에 vocab_size가 들어가는 이유는?\n",
    "    # positional encoding의 첫 이자는 최대 시퀀스 길이를 의미\n",
    "    # 실제 입력 시퀀스 길이가 vocab_size보다 짧다면 문제 없다.\n",
    "    # gpt : vocab_size가 아니라 max_seq_len을 전달하는 편이 좋다.\n",
    "    embeddings = PositionalEncoding(max_legnth, d_model)(embeddings)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(units=units,\n",
    "                               d_model=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               dropout=dropout,\n",
    "                               name=\"encoder_layer_{}\".format(i),\n",
    "                               )([outputs, padding_mask])\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd266914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    # look_ahead_mask는 디코더의 self-attention에서 사용한다.\n",
    "    # look_ahed_mask의 shape는 (batch, 1, seq_len_query, seq_len_key)\n",
    "    # self-attention에서는 seq_q = seq_k 이기 때문에, (batch, 1, seq_len, seq_len) \n",
    "    look_ahead_mask = tf.keras.Input(shape=(1,None,None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': look_ahead_mask\n",
    "    })\n",
    "    \n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1+inputs)\n",
    "    \n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "        'query': attention1,\n",
    "        'key': enc_outputs,\n",
    "        'value': enc_outputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "    \n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2+attention1)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e1babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, max_legnth, name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 인코더와 같은 vocab size\n",
    "    embeddings = PositionalEncoding(max_legnth, d_model)(embeddings)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units = units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "        \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec80a2e",
   "metadata": {},
   "source": [
    "데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "509dc9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path_to_zip = tf.keras.utils.get_file(\\n    \\'cornell_movie_dialogs.zip\\',\\n    origin=\\'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\\',\\n    extract=True)\\n\\npath_to_dataset = os.path.join(\\n    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\\n\\npath_to_movie_lines = os.path.join(path_to_dataset, \\'movie_lines.txt\\')\\npath_to_movie_conversations = os.path.join(path_to_dataset,\\'movie_conversations.txt\\')'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a597e427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAX_SAMPLES = 50000\\n\\ndef preprocess_sentence(sentence):\\n    sentence = sentence.strip().lower()\\n    \\n    sentence = re.sub(r\"([?.!,])\", r\" \\x01 \", sentence)\\n    sentence = re.sub(r\\'[\" \"]\\', \" \", sentence)\\n    \\n    sentence = re.sub(r\"[^a-zA-Z.?!,]\", \\' \\', sentence)\\n    sentence = sentence.strip()\\n    return sentence'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"MAX_SAMPLES = 50000\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.strip().lower()\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]', \" \", sentence)\n",
    "    \n",
    "    sentence = re.sub(r\"[^a-zA-Z.?!,]\", ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f39aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\\ndef load_conversations():\\n    id2line = {}\\n    with open(path_to_movie_lines, errors='ignore') as file:\\n        lines = file.readlines()\\n    for line in lines:\\n        parts = line.replace('\\n', '').split(' +++$+++ ')\\n        id2line[parts[0]] = parts[4]\\n\\n    inputs, outputs = [], []\\n    with open(path_to_movie_conversations, 'r') as file:\\n        lines = file.readlines()\\n\\n    for line in lines:\\n        parts = line.replace('\\n', '').split(' +++$+++ ')\\n        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\\n\\n        for i in range(len(conversation) - 1):\\n            # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\\n            inputs.append(preprocess_sentence(id2line[conversation[i]]))\\n            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\\n\\n            if len(inputs) >= MAX_SAMPLES:\\n                return inputs, outputs\\n    return inputs, outputs\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfdb6de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"questions, answers = load_conversations()\\nprint('전체 샘플 수 :', len(questions))\\nprint('전체 샘플 수 :', len(answers))\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5f4cf196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = \"./data/ChatbotData.csv\"\n",
    "dataframe = pd.read_csv(path_to_dataset)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d447a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 특수문자 제거\n",
    "    sentence = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s]', ' ', sentence)\n",
    "    # 중복 문자 정규화\n",
    "    sentence = re.sub(r'(.)\\1{2,}', r'\\1\\1', sentence)\n",
    "    # ?.!, 띄어쓰기\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "14925981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "questions = dataframe['Q'].apply(preprocess_sentence)\n",
    "answers = dataframe['A'].apply(preprocess_sentence)\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18aaf40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              12시 땡\n",
      "1        1지망 학교 떨어졌어\n",
      "2       3박4일 놀러가고 싶다\n",
      "3    3박4일 정도 놀러가고 싶다\n",
      "4            PPL 심하네\n",
      "Name: Q, dtype: object\n",
      "0     하루가 또 가네요\n",
      "1      위로해 드립니다\n",
      "2    여행은 언제나 좋죠\n",
      "3    여행은 언제나 좋죠\n",
      "4     눈살이 찌푸려지죠\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b095f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import koeda\n",
    "augmenter = koeda.EDA(morpheme_analyzer=\"Okt\", alpha_sr=0.3, alpha_ri=0.1, alpha_rs=0.1, prob_rd=0.1)\n",
    "aug_questions, aug_answers = [], []\n",
    "for q, a in zip(questions, answers):\n",
    "    aug_q = augmenter(q, repetition=3)\n",
    "    for aug in aug_q:\n",
    "        aug_questions.append(str(aug))\n",
    "        aug_answers.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dc791969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 수: 11823\n",
      "증강 데이터 수: 35469\n"
     ]
    }
   ],
   "source": [
    "aug_df= pd.DataFrame({'question': aug_questions,\n",
    "                                'answer':aug_answers})\n",
    "\n",
    "print(f\"원본 데이터 수: {len(questions)}\")\n",
    "print(f\"증강 데이터 수: {len(aug_questions)}\")\n",
    "#print(f\"최종 학습 데이터 수: {len(all_questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "99ba6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df = aug_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "055b944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>말문이 탁 막힌다</td>\n",
       "      <td>생각지도 못한 일이 일어났나봐요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>썸 기 타는 기간</td>\n",
       "      <td>정해져 있지는 않지만 발전된 관계가 좋겠죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>어제 또 톡보내버렸네</td>\n",
       "      <td>달라지지 않는다면 연락은 하지마세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이승로 짝남 보내기로 했어요</td>\n",
       "      <td>힘든 결정이었을텐데 맘고생 많았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>휴학할까</td>\n",
       "      <td>계획 세우고 하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>양배추즙맛없어</td>\n",
       "      <td>먹으면서 다이어트 하는 분들 진짜 엄청 대단한 분들이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여자친구가 스킨십 등기 싫대</td>\n",
       "      <td>좀 더 기다려주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>꿈에 나온 여자를 촉망 어떻게 찾을 수 있을까</td>\n",
       "      <td>서울에서 왕서방 찾기네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>매일 그녀 꿈을 꾸네</td>\n",
       "      <td>그녀 생각이 많이 나서 그럴거예요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>처음엔 좋았는데</td>\n",
       "      <td>그 사람의 좋은점을 생각해보세요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question                           answer\n",
       "0                  말문이 탁 막힌다                생각지도 못한 일이 일어났나봐요\n",
       "1                  썸 기 타는 기간          정해져 있지는 않지만 발전된 관계가 좋겠죠\n",
       "2                어제 또 톡보내버렸네              달라지지 않는다면 연락은 하지마세요\n",
       "3            이승로 짝남 보내기로 했어요              힘든 결정이었을텐데 맘고생 많았어요\n",
       "4                       휴학할까                       계획 세우고 하세요\n",
       "5                    양배추즙맛없어  먹으면서 다이어트 하는 분들 진짜 엄청 대단한 분들이에요\n",
       "6            여자친구가 스킨십 등기 싫대                       좀 더 기다려주세요\n",
       "7  꿈에 나온 여자를 촉망 어떻게 찾을 수 있을까                    서울에서 왕서방 찾기네요\n",
       "8                매일 그녀 꿈을 꾸네               그녀 생각이 많이 나서 그럴거예요\n",
       "9                   처음엔 좋았는데                그 사람의 좋은점을 생각해보세요"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 학습 데이터 수: 35469\n",
      "말문이 탁 막힌다 생각지도 못한 일이 일어났나봐요\n"
     ]
    }
   ],
   "source": [
    "display(aug_df.head(10))\n",
    "questions = aug_df['question']\n",
    "answers = aug_df['answer']\n",
    "\n",
    "print(f\"최종 학습 데이터 수: {len(questions)}\")\n",
    "print(questions[0], answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "10a38f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question    0\n",
      "answer      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(aug_df.isnull().sum())\n",
    "aug_df = aug_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "660a34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e750cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [650, 1934, 10, 1072, 8437, 8362, 8346, 94]\n",
      "기존 문장: 결혼해서도 설렐까\n",
      "650 ----> 결혼\n",
      "1934 ----> 해서\n",
      "10 ----> 도 \n",
      "1072 ----> 설\n",
      "8437 ----> �\n",
      "8362 ----> �\n",
      "8346 ----> �\n",
      "94 ----> 까\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))\n",
    "\n",
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d4b8d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "            \n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7845853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8460\n",
      "필터링 후의 질문 샘플 개수: 35469\n",
      "필터링 후의 답변 샘플 개수: 35469\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0f4d6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] \n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    }))\n",
    "\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1201f",
   "metadata": {},
   "source": [
    "    트랜스포머 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "02477623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, units, d_model, num_heads, dropout, max_length, name='transformer'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name='dec_inputs')\n",
    "    \n",
    "    # 인코더 패딩\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape = (1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "    # 디코더 패딩, 셀프어텐션부분\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "    # 디코더 패딩, 크로스어텐션부분\n",
    "    # dec_padding_mask의 input이 인코더패딩의 input과 같은 이유?\n",
    "    # 디코더의 크로스 어텐션 레이어가 인코더 출력의 패딩 토큰을 무시하기 위해 필요하기 때문\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "    \n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        max_legnth=max_length)(inputs=[inputs, enc_padding_mask])\n",
    "    \n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        max_legnth=max_length)(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2ae80",
   "metadata": {},
   "source": [
    "    모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5ade1a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3219968     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3747328     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8460)   2174220     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,141,516\n",
      "Trainable params: 9,141,516\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    max_length = MAX_LENGTH)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a546838",
   "metadata": {},
   "source": [
    "    손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1371206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    # y_true를 (배치*시퀀스 길이) 형태로 재구성\n",
    "    # MAX_LENGTH - 1 의 이유 : 디코더 출력에서 <START> 토큰을 제외한 길이만큼 예측\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH -1))\n",
    "    \n",
    "    # from_logits=True : y_pred가 softmax를 거치지 않았음을 명시\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    \n",
    "    # 패딩 토큰 위치를 마스킹하는 mask\n",
    "    mask  = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    # 각 위치별 손실에 마스크를 곱해 패딩위치의 손실을 0으로\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    # 전체 손실의 평균값 반환\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "98a254f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e9566b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyBElEQVR4nO3deZxcVZ3//9en9+4k3Uk6nZA9gYQlIAg0GVBUBJXgFpcwJsPMoKJ8HWHcZr4OjMv4ZYbvT9SvfNVBEYUBfaABUb9EjUaGRRGB0MiaQKBJAknIvnRn6+qu7s/vj3uqU2mququr6/ZW7+fjUY++de65556qdO6nz3LPNXdHRESk0EqGugIiIjI6KcCIiEgsFGBERCQWCjAiIhILBRgREYlF2VBXYChNmjTJ58yZM9TVEBEZUR5//PFd7t7QV76iDjBz5syhqalpqKshIjKimNnLueRTF5mIiMRCAUZERGKhACMiIrFQgBERkVgowIiISCxiDTBmtsjM1plZs5ldlWF/pZndEfY/amZz0vZdHdLXmdmFaem3mNkOM3s2yzn/yczczCbF8qFERCQnsQUYMysFbgAuAhYAy8xsQY9slwF73X0ecD1wXTh2AbAUOBlYBHw3lAdwa0jLdM6ZwDuAVwr6YUREpN/ibMEsBJrdfb27twPLgcU98iwGbgvbdwEXmJmF9OXunnD3DUBzKA93/yOwJ8s5rwc+DwzJMwi2t7bx+zXbhuLUIiLDTpwBZjqwKe395pCWMY+7J4EWoD7HY49iZouBLe7+VB/5LjezJjNr2rlzZy6fI2d/+8NHufzHj5NIdha0XBGRkWhUDPKbWQ3wr8CX+8rr7je5e6O7NzY09LnSQb9s3nsYgNbDyYKWKyIyEsUZYLYAM9PezwhpGfOYWRlQB+zO8dh0xwFzgafMbGPI/xczO2YA9e+36opomKjlcMdgnlZEZFiKM8A8Bsw3s7lmVkE0aL+iR54VwKVhewlwn0fPcF4BLA2zzOYC84HV2U7k7s+4+2R3n+Puc4i61M5w90EdEKkuTwWY9sE8rYjIsBRbgAljKlcCq4DngDvdfY2ZXWNm7w3ZbgbqzawZ+BxwVTh2DXAnsBb4HXCFu3cCmNlPgYeBE8xss5ldFtdn6K9UC2bfIbVgRERiXU3Z3VcCK3ukfTltuw24OMux1wLXZkhflsN55/S3roWQasEowIiIjJJB/uGiO8BoDEZERAGmkCrKoq+z5ZDGYEREFGAKqL2zC1ALRkQEFGAKKpEMAUZjMCIiCjCFlOiI7uBXC0ZERAGmoFJdZBqDERFRgCmoRIfGYEREUhRgCkhjMCIiRyjAFFBqFeXWtg46u4bkiQEiIsOGAkwBJZJdVJaV4A6t6iYTkSKnAFMg7k57soupdVUA7NFAv4gUOQWYAkmNv0wbXw3Arv2JoayOiMiQU4ApkJ4BZvdBtWBEpLgpwBRIaoB/eqoFc0AtGBEpbgowBdIeWjDH1FVhBrsOqAUjIsVNAaZAUl1kNRWlTKypUAtGRIqeAkyBpO7irywrpX5sBbsVYESkyCnAFEhqDKayvIRJYyvZrS4yESlyCjAFkuoiqywtoX5spbrIRKToxRpgzGyRma0zs2YzuyrD/kozuyPsf9TM5qTtuzqkrzOzC9PSbzGzHWb2bI+yvm5mz5vZ02b2SzMbH+dn66k7wJSXMGlshVowIlL0YgswZlYK3ABcBCwAlpnZgh7ZLgP2uvs84HrgunDsAmApcDKwCPhuKA/g1pDW0z3AKe5+KvACcHVBP1AfUs+CqSwrZdLYSvYnkrSFNBGRYhRnC2Yh0Ozu6929HVgOLO6RZzFwW9i+C7jAzCykL3f3hLtvAJpDebj7H4E9PU/m7r9392R4+wgwo9AfqDfdLZiyEurHVAC62VJEilucAWY6sCnt/eaQljFPCA4tQH2Ox/bmo8BvM+0ws8vNrMnMmnbu3NmPInvXnjwyi6xhXCUAO7VcjIgUsVE3yG9mXwCSwO2Z9rv7Te7e6O6NDQ0NBTtv+hjMlNpowcttLW0FK19EZKSJM8BsAWamvZ8R0jLmMbMyoA7YneOxr2FmHwbeDVzi7oP6QJbuacplJd0rKm9rOTyYVRARGVbiDDCPAfPNbK6ZVRAN2q/okWcFcGnYXgLcFwLDCmBpmGU2F5gPrO7tZGa2CPg88F53P1TAz5GTRFoX2cQxFVSUlrC1VS0YESlesQWYMKZyJbAKeA64093XmNk1ZvbekO1moN7MmoHPAVeFY9cAdwJrgd8BV7h7J4CZ/RR4GDjBzDab2WWhrP8ExgH3mNmTZnZjXJ8tk9Sd/BVlJZgZU+oq2a4uMhEpYmVxFu7uK4GVPdK+nLbdBlyc5dhrgWszpC/Lkn/egCo7QIlkJ2UlRmmJATC1tpqtCjAiUsRG3SD/UEk9LjllSl0V29RFJiJFTAGmQBLJTirLS7vfT62rYltLG4M810BEZNhQgCmQREePFkxtFYlkF/sOdQxhrUREho4CTIG0dx4dYLqnKqubTESKlAJMgUQtmCNdZMfU6WZLESluCjAFEo3BHPk6p9VVA7Bln262FJHipABTID1nkU0eV0lFaQmb9g76PZ8iIsOCAkyBJJJdVKQFmJISY8aEajbtUYARkeKkAFMgiWTnUWMwADMn1rBpj7rIRKQ4KcAUSM9pygAzJ1bzilowIlKkFGAKpOcYDMDMCTW0HO6g5bDuhRGR4qMAUyDtya7XdJHNmlgDoHEYESlKCjAF0nOaMkRjMACbNZNMRIqQAkyBZOwi627BaKBfRIqPAkyBJDJ0kdVVl1NbVcbLew4OUa1ERIaOAkwBJDu76Ozy17RgAOZOGsPGXeoiE5HiowBTAKnHJVdkCDDHTR7LSzsPDHaVRESGnAJMAaQCTKYWzHENY9na0saBRHKwqyUiMqQUYAogkewEOOqBYynHNYwFYL1aMSJSZGINMGa2yMzWmVmzmV2VYX+lmd0R9j9qZnPS9l0d0teZ2YVp6beY2Q4ze7ZHWRPN7B4zezH8nBDnZ0uX6Mjegpk3eQyAuslEpOjEFmDMrBS4AbgIWAAsM7MFPbJdBux193nA9cB14dgFwFLgZGAR8N1QHsCtIa2nq4B73X0+cG94PyjaO1MB5rUtmFkTx1BaYry0QzPJRKS4xNmCWQg0u/t6d28HlgOLe+RZDNwWtu8CLjAzC+nL3T3h7huA5lAe7v5HYE+G86WXdRvwvgJ+ll711oKpKCthdn2NWjAiUnTiDDDTgU1p7zeHtIx53D0JtAD1OR7b0xR33xq2twFTMmUys8vNrMnMmnbu3JnL5+jTkTGYzF/ncQ2aSSYixWdUDvK7uwOeZd9N7t7o7o0NDQ0FOd+RWWSv7SIDmDd5LBt2HaQ95BMRKQZxBpgtwMy09zNCWsY8ZlYG1AG7czy2p+1mNjWUNRXYkXfN+ynVgsl0HwzASVNr6eh0tWJEpKjEGWAeA+ab2VwzqyAatF/RI88K4NKwvQS4L7Q+VgBLwyyzucB8YHUf50sv61Lg7gJ8hpz0NgYDsGDqOADWvto6WFUSERlysQWYMKZyJbAKeA64093XmNk1ZvbekO1moN7MmoHPEWZ+ufsa4E5gLfA74Ap37wQws58CDwMnmNlmM7sslPVV4O1m9iLwtvB+UPR2oyXA3EljqSovYe1WBRgRKR5lcRbu7iuBlT3Svpy23QZcnOXYa4FrM6Qvy5J/N3DBQOqbr95utAQoLTFOmDKO5xRgRKSIjMpB/sHW3kcLBmDBtFrWbm0l6gEUERn9FGAKoK8uMoAFU2vZd6iDrS1tg1UtEZEhpQBTAH1NU4ZoJhnAGg30i0iRUIApgERHJ2ZQXmpZ8yyYVkuJwdOb9w1exUREhpACTAGkHpccrXKTWU1FGSceU8sTr+wbvIqJiAyhPgOMmR1vZvemVi82s1PN7IvxV23kSCS7qCjtO1afPms8T23aR1eXBvpFZPTLpQXzA+BqoAPA3Z8mumlSgkSyM+sU5XSnz5rA/kRSd/SLSFHIJcDUuHvPu+j1eMY0iY6uXmeQpZw+azyAuslEpCjkEmB2mdlxhMUjzWwJsLX3Q4pLagymL3Prx1BXXc4Tm/YOQq1ERIZWLnfyXwHcBJxoZluADcAlsdZqhIkCTN9dZCUlxutnjufxlxVgRGT0y6UF4+7+NqABONHdz83xuKIRjcHk9pUsnDuRF7YfYPeBRMy1EhEZWrlcFX8O4O4H3X1/SLsrviqNPLl2kQGcc1w9AI+sz/RQThGR0SNrF5mZnQicDNSZ2QfSdtUCVXFXbCRJJLsYX12eU97XTa9jTEUpD6/fxbtOnRpzzUREhk5vYzAnAO8GxgPvSUvfD3w8xjqNOImOTirGVeaUt7y0hIVzJ/Lnl3bHXCsRkaGVNcC4+93A3WZ2jrs/PIh1GnHa+9FFBlE32f3rdrK9tY0ptWoMisjolMsssifM7Aqi7rLuq6G7fzS2Wo0wuc4iSznn2EkAPPzSbt53+vS4qiUiMqRy+bP7x8AxwIXAH4AZRN1kEvRnFhlEC1/Wj6nggXU7YqyViMjQyuWqOM/dvwQcdPfbgHcBfxVvtUaW/swig+gJl285oYEHXthJp9YlE5FRKperYkf4uc/MTgHqgMnxVWnk6W8XGcAFJ05h36EOnnhFN12KyOiUS4C5ycwmAF8EVgBrgetirdUI4u79HuQHeNPxkygrMe59Xt1kIjI69XlVdPcfuvted/+jux/r7pOB3+ZSuJktMrN1ZtZsZldl2F9pZneE/Y+a2Zy0fVeH9HVmdmFfZZrZBWb2FzN70sz+ZGbzcqnjQHU/zbIfYzAAtVXlnDVnIvc9pwAjIqNTr1dFMzvHzJaY2eTw/lQz+wnwUF8Fm1kpcANwEbAAWGZmC3pkuwzY6+7zgOsJLaOQbynRzLVFwHfNrLSPMr8HXOLurwd+QtTiil0uj0vO5oKTJrNu+35e3n2w0NUSERlyWQOMmX0duAX4IPAbM/sP4PfAo8D8HMpeCDS7+3p3bweWA4t75FkM3Ba27wIusOixkIuB5e6ecPcNQHMor7cynWiVAYjGiV7NoY4Dlkh2AlDRzy4ygEWnHAPAr5/W4tQiMvr0dh/Mu4DT3b0tjMFsAk5x9405lj09HJOymdfOPuvO4+5JM2sB6kP6Iz2OTd0wkq3MjwErzeww0AqcnalSZnY5cDnArFmzcvwo2SU6Ui2Y/geYGRNqOH3WeH799FaueOug9OiJiAya3q6Kbe7eBuDue4EX+xFchsJngXe6+wzgv4BvZsrk7je5e6O7NzY0NAz4pEe6yPJbYPrdp07jua2tesqliIw6vV0VjzWzFakXMLfH+75sAWamvZ8R0jLmMbMyoq6t3b0cmzHdzBqA09z90ZB+B/CGHOo4YKkusnzGYADe9bqpmMFv1E0mIqNMb11kPcdL/k8/y34MmG9mc4kCw1Lgb3rkWQFcCjwMLAHuc3cPAewnZvZNYBrRmM9qwLKUuZdo1efj3f0F4O3Ac/2sb17a85xFlnJMXRVnzZ7I3U9u4R/Pn0c0BCUiMvL1ttjlHwZScBhTuRJYBZQCt7j7GjO7Bmhy9xXAzcCPzawZ2EMUMAj57iS65yYJXOHunQCZygzpHwd+bmZdRAFnUNZKG2gXGcAHz5zOv/z8Gf7yyl7OnD2xUFUTERlSuSx2mTd3Xwms7JH25bTtNuDiLMdeC1ybS5kh/ZfALwdY5X4byDTllHefOo1rfrWWOx7bpAAjIqOGHn08QImO1BhM/l/lmMoy3nPaNH711Fb2t3X0fYCIyAigADNAhegiA/jrs2ZyuKNT98SIyKjRZxeZmf2K6CbGdC1AE/D91FTmYlWILjKA02eO54Qp4/jRwy+z9KyZGuwXkREvlz+71wMHgB+EVyvR82COD++LWvc05TxnkaWYGR954xye29rKw+v1OGURGflyuSq+wd3/xt1/FV5/C5zl7lcAZ8Rcv2FvIHfy9/S+06dTP6aCW/60YcBliYgMtVyuimPNrHtNlbA9Nrxtj6VWI0h7Z2G6yACqyku55OzZ3Pv8Dtbrzn4RGeFyCTD/BPzJzO43sweAB4F/NrMxHFmosmilWjD5LHaZyd+dPZvykhJ+qFaMiIxwfQ7yu/tKM5sPnBiS1qUN7P/fuCo2UiSSnZSXGqUlhRmUbxhXycWNM7izaROfPO84ZkyoKUi5IiKDLdc/u88kejbLacBfm9nfx1elkSWfxyX35Yq3zsMwbrj/pYKWKyIymPoMMGb2Y+AbwLnAWeHVGHO9RoxEsrMgA/zppo2v5kNnzeRnTZvYtOdQQcsWERksuSwV0wgscPee98II0RhMocZf0n3yrcdxx2Ob+Pa9L/L1i08rePkiInHL5cr4LHBM3BUZqaIussIHmKl11fzdObO56y+bWfNqS8HLFxGJWy5XxknAWjNb1c/nwRSFqIussGMwKZ86fz7jq8u55ldrUQNSREaaXLrIvhJ3JUayRLJrwHfxZ1NXU87n3n48X7p7DavWbGfRKWpIisjIkcs05QE9F2a0a4+piyxl2cJZ/Ojhl7l25VrecnwD1RXxtJZERAot65XRzP4Ufu43s9a0134zax28Kg5vcUxTTldWWsK/v+8UNu05zPX//UJs5xERKbSsAcbdzw0/x7l7bdprnLvXDl4Vh7c4pin3dPax9SxbOIsfPriepzfvi/VcIiKFktOV0cxKzWyamc1KveKu2EiR6IhvDCbdVRedyKSxlXz+rqdpD48IEBEZznK50fIfge3APcBvwuvXMddrxEgku6gojT/A1FWX8x/vO4Xnt+3nm/eoq0xEhr9croyfBk5w95Pd/XXhdWouhZvZIjNbZ2bNZnZVhv2VZnZH2P+omc1J23d1SF9nZhf2VaZFrjWzF8zsOTP7VC51HKg4pyn39I6Tj2HZwpl8/48v8VDzrkE5p4hIvnIJMJuInmDZL2ZWCtwAXAQsAJaZ2YIe2S4D9rr7POB64Lpw7AJgKdH6Z4uA74Zuut7K/DAwEzjR3U8Clve3zvmIc5pyJl969wKOnTSGz97xJHsOFv3TEkRkGMv1iZYPhBbF51KvHI5bCDS7+3p3bye64C/ukWcxR5b8vwu4wKJnBS8Glrt7wt03AM2hvN7K/AfgGnfvAnD3HTnUccASHfFOU+6ppqKM7yw7g32HOvj08ifo7NINmCIyPOVyZXyFaPylAhiX9urLdKLWT8rmkJYxj7sniVpK9b0c21uZxwEfMrMmM/tteMTAa5jZ5SFP086dO3P4GL1r74x3mnImC6bV8r8Wn8yDL+7ia797flDPLSKSq15vtAxdUse7+yWDVJ+BqATa3L3RzD4A3AK8qWcmd78JuAmgsbFxQH/+Jzu76OzyQW3BpCxbOIu1r7by/T+u56Sptbzv9J6xW0RkaPV6ZXT3TmC2mVXkUfYWojGRlBkhLWMeMysD6oDdvRzbW5mbgV+E7V8COU1EGIhEmC48mGMw6b78ngUsnDuRf/n50zRt3DMkdRARySbXMZiHzOxL/RyDeQyYb2ZzQ4BaCvRcJHMFcGnYXgLcFx4LsAJYGmaZzQXmA6v7KPP/AW8N228BYp/L2x1gBrmLLKW8tITvXXIG08ZXc9ltTbywff+Q1ENEJJNcAsxLRPe9lNCPMZgwpnIlsAp4DrjT3deY2TVm9t6Q7Wag3syagc8BV4Vj1wB3AmuB3wFXuHtntjJDWV8FPmhmzwD/H/CxHD7bgCSSnQBD0kWWUj+2kh99dCEVZSVcestqtrYcHrK6iIiks2JeBr6xsdGbmpryPn7jroOc940H+OZfn8YHzphRwJr135pXW/jQ9x9h8rhKfnr52UyprRrS+ojI6GVmj7t7n082zuVO/gYz+7qZrTSz+1KvwlRzZBvqLrJ0J0+r49aPnMX21jaW3fQI21vbhrpKIlLkcunbuR14HpgL/C9gI9FYSNEbDl1k6RrnTOS2jy5ke2sbS296hG0tCjIiMnRyuTLWu/vNQIe7/8HdPwqcH3O9RoShnkWWSeOcifzosoXs3J/gg9/7M807NPAvIkMjlytjR/i51czeZWanAxNjrNOI0T6MusjSnTl7Ij/9+Nkkkp188HsPawqziAyJXALMf5hZHfBPwD8DPwQ+G2utRojh1kWW7nUz6vjFP7yRiWMquOSHj7Lyma1DXSURKTJ9Xhnd/dfu3uLuz7r7W939THfveT9LUUp0DL8usnSz6mu46xPnsGBaLZ+8/S98fdXzWrtMRAZNLrPIjjeze83s2fD+VDP7YvxVG/6G0yyybOrHVrL88rP5UONMbrj/JS677TFaDnf0faCIyADl8qf3D4CrCWMx7v400R30RS/VRVYxDLvI0lWWlfLVD76Oa99/Cg817+I93/kTT7yyd6irJSKjXC5Xxhp3X90jLRlHZUaaIy2Y4R1gAMyMS/5qNssvP4fOLufiGx/mhvub1WUmIrHJ5cq4y8yOAxzAzJYAGjEmbQxmBASYlDNnT2Dlp9/EolOO4eur1vE3P3iEzXsPDXW1RGQUyuXKeAXwfeBEM9sCfAb4RJyVGimOzCIbvmMwmdRVl/OdZafzjYtP49ktLbzj+j9y60Mb1JoRkYLKZRbZend/G9BA9Djic4H3x16zEaA92YUZlJfaUFel38yMJWfOYNVn38xZcybylV+t5eIb/8yLWpFZRAok574ddz/o7qmrTy7L9Y96iWT0uOToKc8j04wJNdz6kbO4/kOnsWHXQd757Qf53yufo7VNM81EZGDyHTwYuVfUAooCzMjqHsvEzHj/6TO453Nv4f2nT+cHD67n/G88wJ2PbaJL3WYikqd8A4yuOkRjMCNpgL8vk8ZW8rUlp3H3FW9kdv0YPv/zp1l8w0M8+OJOivmxDiKSn6xXRzPbb2atGV77gWmDWMdhK9HRNWzv4h+IU2eM565PnMO3lr6ePQfb+bubV7P0pke0ppmI9EtZth3u3udTK4tdItlFRenoCzAQdZstfv10Fp1yDMtXb+I79zWz5MaHOe+EBj51wXzOmDVhqKsoIsPc6Lw6DpKoi2zkj8H0prKslEvfMIcHP/9WrrroRJ7ctI8PfPfP/PX3H+b+53eo60xEslKAGYBEcnR2kWVSXVHKJ95yHH/6l/P54rtOYtOeQ3zk1se46FsP8ssnNtPR2TXUVRSRYSbWq6OZLTKzdWbWbGZXZdhfaWZ3hP2PmtmctH1Xh/R1ZnZhP8r8tpkdiO1DpUlNUy4mYyvL+NibjuUP//OtfOPi0+jscj57x1O88av3cf09L+hRzSLSLbaro5mVAjcAFwELgGVmtqBHtsuAve4+D7geuC4cu4BoQc2TgUXAd82stK8yzawRGLTBgdEyTTkfFWUl0Y2an3kzt3y4kZOm1vKte1/kDV+9j0/e/jgPv7Rb3WciRS7rIH8BLASa3X09gJktBxYDa9PyLAa+ErbvAv7TorsWFwPL3T0BbDCz5lAe2coMwefrwN8wSCsNJDo6qRxXORinGrZKSozzT5zC+SdO4eXdB7n90Ve4s2kTK5/ZxrGTxvDBM2fw/tOnM2189VBXVUQGWZz9O9OBTWnvN4e0jHncPQm0APW9HNtbmVcCK9y914U4zexyM2sys6adO3f26wP11J7sorK8OFswmcyuH8O/vvMkHrn6Ar5x8WlMGlfJ11et443X3cclP3yEnz++mUPtWohbpFjE2YIZNGY2DbgYOK+vvO5+E3ATQGNj44D6cIpxDCYXVeWlLDlzBkvOnMEruw/xiyc284u/bOGffvYUX7r7Wd520hTe+bqpnHdCA1UK0CKjVpwBZgswM+39jJCWKc9mMysD6oDdfRybKf10YB7QHNYFqzGz5jC2E5tEsnPYP2xsqM2qr+EzbzueT18wn8c27uWXT2zmd89uY8VTr1JTUcr5J07mXa+bynknTKa6QsFGZDSJM8A8Bsw3s7lEQWAp0fhIuhXApcDDwBLgPnd3M1sB/MTMvkm0asB8YDXRGmivKdPd1wDHpAo1swNxBxcId/IrwOTEzFg4dyIL507k3xefwiPr97Dy2a2senYbv356K9XlpZx3QgPnnziZ806YTEORj22JjAaxBRh3T5rZlcAqoBS4xd3XmNk1QJO7rwBuBn4cBvH3EB7FHPLdSTQhIAlc4e6dAJnKjOsz9KWYZ5ENRFlpCefOn8S58ydxzXtPZvXGPax8Ziv3rN3Ob5/dhlm0XM0FJ07m/BMnc/K02hG9YrVIsbJinkra2NjoTU1NeR3b1eUc+68r+fQF8/ns248vcM2Kk7uzdmsr9z23g3uf38FTm/fhDpPHVXLuvEm8Yd4k3jivnql1mpEmMpTM7HF3b+wr36gY5B8K7eHO9WK5k38wmBknT6vj5Gl1/OMF89l1IMED63Zy/7odPPDCTn7xRDQMd2zDmCjgHDeJc46tp66mfIhrLiKZKMDkKZEMAUZdZLGZNLayezZaV5fz/Lb9PNS8i4de2sXPmjbzo4dfpsRgwbRazpozkbPmTKRx9gQm11YNddVFBAWYvCWSnQAa5B8kJSXGgmm1LJhWy8fffCztyS6e3LSPPzXvYvWG3fx09Sv810MbAZhdX0Pj7ImcNWcCjXMmclzDGI3hiAwBBZg8JTpSLRgFmKFQUVbSPSsNopte17zaQtPGvTS9vIcH1u3g53/ZDEBddTmnzqjj1Bl1nDZjPKfNHM8UtXJEYqcAk6dUF5nugxkeKspKOH3WBE6fNYGPcyzuzoZdB3ls4x6e3NTCU5v2ceMf1tMZHgF9TG1VFHBmjufUGdG4z8QxFUP8KURGFwWYPB3pItMYzHBkZhzbMJZjG8byobOitMPtnazd2sJTm1p4avM+nt7cwu/Xbu8+ZkptJSdNreWkqbUsCD/nThpDaYm610TyoQCTp+5Bfs0iGzGqK0o5c/ZEzpw9sTut5VAHz2xp4bmtrTy3tZW1W1v504u7SIaWTlV5CSdMGRcFnWm1nHhMLfMmj1VrRyQHCjB50hjM6FBXU95902dKItlJ844DPLd1f3fgWbVmG8sfO7LOav2YCo6bPJb5k8cyb/JY5k8ex7zJY5lSW6kJBSKBAkyeuu+DURfZqFNZVtp9P06Ku7OttY112/bTvOMAzTsO8OKOA/zqqVdpbTuyQvS4yjKOC0Fn7qQxzJ00hjn1Y5gzqYaaCv13k+Ki3/g8JTo0TbmYmBlT66qZWlfNeSdM7k53d3YeSHQHneYdB3hx+wH+8MJO7np881FlTKmtZE59CDoh8MydNIbZ9TVaVVpGJQWYPKXGYKo0BlPUzIzJ46qYPK6KNxw36ah9+9s6eHn3ITbuPsjGXQfZsCvavmftdnYfbE8rA6aMq2LGhGpmTqyJfk6o6X4/ta6KslL9nsnIowCTJ93JL30ZV1XOKdPrOGV63Wv2tbZ1sHHXQTbuPsTGXQd5Zc8hNu89xOoNe7j7ycN0pS0RWFpiHFNbxcyJ1cyYUPOa4DOltkrT5WVYUoDJk+7kl4GorSrn1BnjOXXG+Nfs6+jsYltLG5v2HGLz3sNs2ht+7jnEgy/uZHtr4qj8ZtGyOtPqqjimrip05UXb08ZXc0xttF2uVpAMMgWYPKVmkekvRym08tISZk6sYebEmoz7E8lOtuw9zOa9h9nacpitLW1s3dfG1tY21u88yJ+bd7M/cfSjqTMFoYZxlTSMq2TyuMqom6+2kok1FZTovh8pEAWYPKmLTIZKZVlp902k2exv62BbSxuvtrSxreUwr+5rC+8PZw1CEHXHTRpbEcaVKplcW0nD2EoaasP7EJQaxlXqd1/6pACTp1QXmVowMhyNqypnXFU586eMy5rncHsnO/cn2LG/jR37E0e2WxPs2J/g1ZY2ntrcwu6DCTI9Nmp8TTmTx1VSP6aS+rEV1I+poH5sJRPHHL09aWwFtVXlahkVIQWYPCWSXZSXmpYRkRGruqKUWfU1zKrP3BWXkuzsYvfBdna0Jth54EgASgWj3QfbWfNqK7sOJNjf9tpWEUQtowk1UbCZGIJP/ZjU9tEBaUJNBbVVZZo5NwoowOSpXY9LliJRVlrClNqqsAL1a2fEpWtPdrH3UDu7DiTYc7Cd3Qfa2X2wnT0HE93buw8keGbzPnYfbM8akABqq8oYX1PBhJpyxtdUML6mnAnh5/jqciaMqYjSq0P6mHLGVZZpJYVhRAEmT4lkp2aQifRQUZYejPqWSHay92AHu0MA2nOwnX2H2tl7qIN9h9rZd7iDvYc62HuonQ27DrL3UO9BqbTEGF9dHgWhEHxqq8upqy6ntqqM2vC+tiqkVZdF2zXljK0oUzdegcUaYMxsEfAtoBT4obt/tcf+SuBHwJnAbuBD7r4x7LsauAzoBD7l7qt6K9PMbgcagQ5gNfA/3L0jrs+W6OhSgBEZoMqyUo6pK+WYutyfz5Ps7KIlBJ6Ww+3sPRgFoCitnX2HOtgXgtLWljZe2LGflkMd7E8kM44lpZhFS/3U1UQB6DVBKBWcqssYV1nO2KoyxlUd2R5bWaYx2R5iCzBmVgrcALwd2Aw8ZmYr3H1tWrbLgL3uPs/MlgLXAR8yswXAUuBkYBrw32Z2fDgmW5m3A38b8vwE+Bjwvbg+XyLZRaWW9xAZdGWlJdEYztjKfh3X1eUcaE/ScqiD1rYOWg8naTmc2g6vtiSthzu60zfsOti9fai9s89zVJaVREGnqpyxlVHQORKIUtvRvnEhfWzl0e/HVJaNmnuW4mzBLASa3X09gJktBxYD6QFmMfCVsH0X8J8WdaAuBpa7ewLYYGbNoTyylenuK1OFmtlqYEZcHwyipn3FKPklECkGJSXW3TLJR0dnV3cQOtCWZH9b1CpKbR9IJNmfSLI/7D+QiNI37TkUtqO0zq5emlFBRWkJYypLqamIglRNZSljK8sYU3FkO9p3JM+YyvR96XnKqCovGZKxqTgDzHRgU9r7zcBfZcvj7kkzawHqQ/ojPY6dHrZ7LdPMyoG/Az49wPr3KmrBKMCIFIvyPFtO6dydto6uHsEpyYFEB/vD9qH2JAcSneFnkkOJTg6G7R2tiSitPcnBRGf3qu59KTEYU3F0EPq39yw46tlIcRiNg/zfBf7o7g9m2mlmlwOXA8yaNSvvk2gMRkT6y8yoriiluqKUyX1n71N7sutIIGrv7A5IR4LQa4PVgfYkhxLJQZkFG2eA2QLMTHs/I6RlyrPZzMqI5kDu7uPYrGWa2b8BDcD/yFYpd78JuAmgsbGx77ZqFolkp57vISJDqqKshIqyaLr2cBTnn+CPAfPNbK6ZVRAN2q/okWcFcGnYXgLc5+4e0peaWaWZzQXmE80My1qmmX0MuBBY5u65tRsHoL1TLRgRkd7E9id4GFO5ElhFNKX4FndfY2bXAE3uvgK4GfhxGMTfQxQwCPnuJJoQkASucPdOgExlhlPeCLwMPBwGs37h7tfE9fkSHRqDERHpTax9PGFm18oeaV9O224DLs5y7LXAtbmUGdIHtb8qoTv5RUR6pT/B86Q7+UVEeqcrZJ6iFoy+PhGRbHSFzFOio0vLQoiI9EJXyDy4e+gi0xiMiEg2CjB5SHY5XY66yEREeqErZB66H5esacoiIlnpCpmH9lSAUReZiEhWCjB5SCSjZbvVRSYikp2ukHlIdKiLTESkL7pC5iGhLjIRkT4pwOQh1UWmB46JiGSnK2QeNItMRKRvukLmoXsMRl1kIiJZKcDkQbPIRET6pitkHtrVRSYi0iddIfOgWWQiIn1TgMmDushERPqmK2QejrRg9PWJiGSjK2QejtzJry4yEZFsFGDyoBstRUT6FusV0swWmdk6M2s2s6sy7K80szvC/kfNbE7avqtD+jozu7CvMs1sbiijOZRZEdfnSiS7MIPyUovrFCIiI15sAcbMSoEbgIuABcAyM1vQI9tlwF53nwdcD1wXjl0ALAVOBhYB3zWz0j7KvA64PpS1N5Qdi0Syi8qyEswUYEREsomzBbMQaHb39e7eDiwHFvfIsxi4LWzfBVxg0VV7MbDc3RPuvgFoDuVlLDMcc34og1Dm++L6YIkOPS5ZRKQvZTGWPR3YlPZ+M/BX2fK4e9LMWoD6kP5Ij2Onh+1MZdYD+9w9mSH/UczscuBygFmzZvXvEwUnTa3lcEdnXseKiBSLohuldveb3L3R3RsbGhryKmPpwll8bclpBa6ZiMjoEmeA2QLMTHs/I6RlzGNmZUAdsLuXY7Ol7wbGhzKynUtERAZRnAHmMWB+mN1VQTRov6JHnhXApWF7CXCfu3tIXxpmmc0F5gOrs5UZjrk/lEEo8+4YP5uIiPQhtjGYMKZyJbAKKAVucfc1ZnYN0OTuK4CbgR+bWTOwhyhgEPLdCawFksAV7t4JkKnMcMp/AZab2X8AT4SyRURkiFj0x39xamxs9KampqGuhojIiGJmj7t7Y1/5im6QX0REBocCjIiIxEIBRkREYqEAIyIisSjqQX4z2wm8nOfhk4BdBaxOoahe/aN69Y/q1T/DtV4wsLrNdvc+71Qv6gAzEGbWlMssisGmevWP6tU/qlf/DNd6weDUTV1kIiISCwUYERGJhQJM/m4a6gpkoXr1j+rVP6pX/wzXesEg1E1jMCIiEgu1YEREJBYKMCIiEg9316ufL2ARsI7oUc5XxVD+TKLHD6wF1gCfDulfIXrOzZPh9c60Y64O9VkHXNhXXYG5wKMh/Q6gIse6bQSeCedvCmkTgXuAF8PPCSHdgG+HczwNnJFWzqUh/4vApWnpZ4bym8OxlkOdTkj7Tp4EWoHPDNX3BdwC7ACeTUuL/TvKdo4+6vV14Plw7l8C40P6HOBw2nd3Y77n7+0z9lKv2P/tgMrwvjnsn5NDve5Iq9NG4MnB/L7Ifm0Y8t+vjP8XCn1xHO0voscEvAQcC1QATwELCnyOqalfBGAc8AKwIPyn++cM+ReEelSG/0wvhXpmrStwJ7A0bN8I/EOOddsITOqR9jXCf2jgKuC6sP1O4Lfhl/xs4NG0X9T14eeEsJ36D7E65LVw7EV5/PtsA2YP1fcFvBk4g6MvTLF/R9nO0Ue93gGUhe3r0uo1Jz1fj3L6df5sn7GPesX+bwd8khAIiB4Vckdf9eqx//8AXx7M74vs14Yh//3K+Nn7e/Er9hdwDrAq7f3VwNUxn/Nu4O29/Kc7qg5Ez8s5J1tdwy/OLo5cWI7K10ddNvLaALMOmBq2pwLrwvb3gWU98wHLgO+npX8/pE0Fnk9LPypfjvV7B/BQ2B6y74seF5zB+I6ynaO3evXY937g9t7y5XP+bJ+xj+8r9n+71LFhuyzks97qlZZuwCZg/lB8X2n7UteGYfH71fOlMZj+m070i5WyOaTFwszmAKcTNeEBrjSzp83sFjOb0EedsqXXA/vcPdkjPRcO/N7MHjezy0PaFHffGra3AVPyrNf0sN0zvT+WAj9Nez/U31fKYHxH2c6Rq48S/cWaMtfMnjCzP5jZm9Lq29/z5/t/Ju5/u+5jwv6WkD8XbwK2u/uLaWmD+n31uDYMy98vBZhhzMzGAj8HPuPurcD3gOOA1wNbiZrog+1cdz8DuAi4wszenL7Toz9vfAjqRXiM9nuBn4Wk4fB9vcZgfEf9PYeZfYHo6bG3h6StwCx3Px34HPATM6uN6/wZDMt/uzTLOPoPmUH9vjJcG/IuKx+5nkMBpv+2EA20pcwIaQVlZuVEv0C3u/svANx9u7t3unsX8ANgYR91ypa+GxhvZmU90vvk7lvCzx1Eg8ILge1mNjXUeyrRwGg+9doStnum5+oi4C/uvj3Ucci/rzSD8R1lO0evzOzDwLuBS8KFA3dPuPvusP040fjG8Xmev9//Zwbp3677mLC/LuTvVcj7AaIB/1R9B+37ynRtyKOsQfn9UoDpv8eA+WY2N/zFvBRYUcgTmJkBNwPPufs309KnpmV7P/Bs2F4BLDWzSjObC8wnGqjLWNdwEbkfWBKOv5SoL7eveo0xs3GpbaLxjmfD+S/NUNYK4O8tcjbQEprYq4B3mNmE0PXxDqJ+8a1Aq5mdHb6Dv8+lXmmO+qtyqL+vHgbjO8p2jqzMbBHweeC97n4oLb3BzErD9rFE39H6PM+f7TP2Vq/B+LdLr+8S4L5UgO3D24jGKbq7kgbr+8p2bcijrEH5/SroYHSxvIhmZrxA9FfKF2Io/1yi5ufTpE3TBH5MNH3w6fCPPTXtmC+E+qwjbeZVtroSzbZZTTQV8WdAZQ71OpZods5TRFMkvxDS64F7iaYv/jcwMaQbcEM49zNAY1pZHw3nbgY+kpbeSHQxeQn4T3KYphyOG0P012ddWtqQfF9EQW4r0EHUh33ZYHxH2c7RR72aifriU79nqVlVHwz/xk8CfwHek+/5e/uMvdQr9n87oCq8bw77j+2rXiH9VuATPfIOyvdF9mvDkP9+ZXppqRgREYmFushERCQWCjAiIhILBRgREYmFAoyIiMRCAUZERGKhACPST2ZWb2ZPhtc2M9uS9r6ij2Mbzezb/TzfR83sGYuWTXnWzBaH9A+b2bSBfBaROGmassgAmNlXgAPu/o20tDI/svbVQMufAfyBaAXdlrBESIO7bzCzB4gWhGwqxLlECk0tGJECMLNbzexGM3sU+JqZLTSzhy1a/PDPZnZCyHeemf06bH/FooUcHzCz9Wb2qQxFTwb2AwcA3P1ACC5LiG6Iuz20nKrN7EyLFlp83MxW2ZFlPR4ws2+FfM+a2cIM5xEpOAUYkcKZAbzB3T9H9BCvN3m0+OGXgf+d5ZgTgQuJ1tr6N4vWmUr3FLAd2GBm/2Vm7wFw97uAJqL1w15PtFDld4Al7n4m0cOyrk0rpybk+2TYJxK7sr6ziEiOfubunWG7DrjNzOYTLe3RM3Ck/MbdE0DCzHYQLYHevcaVu3eG9cLOAi4ArjezM939Kz3KOQE4BbgnWkKKUqJlTlJ+Gsr7o5nVmtl4d9+X/0cV6ZsCjEjhHEzb/nfgfnd/v0XP7XggyzGJtO1OMvyf9GigdDWw2szuAf6L6IFc6QxY4+7nZDlPz8FWDb5K7NRFJhKPOo4sc/7hfAsxs2lmdkZa0uuBl8P2fqLH5kK08GODmZ0Tjis3s5PTjvtQSD+XaEXdlnzrJJIrtWBE4vE1oi6yLwK/GUA55cA3wnTkNmAn8Imw71bgRjM7TPQo4CXAt82sjuj/9v8lWuEXoM3MngjlfXQA9RHJmaYpi4xyms4sQ0VdZCIiEgu1YEREJBZqwYiISCwUYEREJBYKMCIiEgsFGBERiYUCjIiIxOL/BxWPw2YhM9c1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bf00e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7c6c6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "555/555 [==============================] - 37s 56ms/step - loss: 1.1248 - accuracy: 0.0238\n",
      "Epoch 2/50\n",
      "555/555 [==============================] - 31s 56ms/step - loss: 0.8688 - accuracy: 0.0334\n",
      "Epoch 3/50\n",
      "555/555 [==============================] - 31s 56ms/step - loss: 0.6768 - accuracy: 0.0512\n",
      "Epoch 4/50\n",
      "555/555 [==============================] - 32s 57ms/step - loss: 0.4650 - accuracy: 0.0751\n",
      "Epoch 5/50\n",
      "555/555 [==============================] - 32s 57ms/step - loss: 0.2702 - accuracy: 0.1009\n",
      "Epoch 6/50\n",
      "555/555 [==============================] - 32s 58ms/step - loss: 0.1436 - accuracy: 0.1209\n",
      "Epoch 7/50\n",
      "555/555 [==============================] - 32s 58ms/step - loss: 0.0875 - accuracy: 0.1307\n",
      "Epoch 8/50\n",
      "555/555 [==============================] - 32s 58ms/step - loss: 0.0648 - accuracy: 0.1349\n",
      "Epoch 9/50\n",
      "555/555 [==============================] - 32s 58ms/step - loss: 0.0443 - accuracy: 0.1396\n",
      "Epoch 10/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0322 - accuracy: 0.1425\n",
      "Epoch 11/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0247 - accuracy: 0.1443\n",
      "Epoch 12/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0203 - accuracy: 0.1454\n",
      "Epoch 13/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0168 - accuracy: 0.1463\n",
      "Epoch 14/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0145 - accuracy: 0.1470\n",
      "Epoch 15/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0121 - accuracy: 0.1475\n",
      "Epoch 16/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0109 - accuracy: 0.1479\n",
      "Epoch 17/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0095 - accuracy: 0.1482\n",
      "Epoch 18/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0085 - accuracy: 0.1485\n",
      "Epoch 19/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0078 - accuracy: 0.1487\n",
      "Epoch 20/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0069 - accuracy: 0.1489\n",
      "Epoch 21/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0065 - accuracy: 0.1490\n",
      "Epoch 22/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0059 - accuracy: 0.1491\n",
      "Epoch 23/50\n",
      "555/555 [==============================] - 34s 61ms/step - loss: 0.0055 - accuracy: 0.1492\n",
      "Epoch 24/50\n",
      "555/555 [==============================] - 42s 75ms/step - loss: 0.0050 - accuracy: 0.1493\n",
      "Epoch 25/50\n",
      "555/555 [==============================] - 44s 80ms/step - loss: 0.0048 - accuracy: 0.1494\n",
      "Epoch 26/50\n",
      "555/555 [==============================] - 44s 80ms/step - loss: 0.0046 - accuracy: 0.1494\n",
      "Epoch 27/50\n",
      "555/555 [==============================] - 45s 81ms/step - loss: 0.0042 - accuracy: 0.1495\n",
      "Epoch 28/50\n",
      "555/555 [==============================] - 36s 65ms/step - loss: 0.0040 - accuracy: 0.1496\n",
      "Epoch 29/50\n",
      "555/555 [==============================] - 33s 60ms/step - loss: 0.0036 - accuracy: 0.1496\n",
      "Epoch 30/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0038 - accuracy: 0.1496\n",
      "Epoch 31/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0034 - accuracy: 0.1497\n",
      "Epoch 32/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0033 - accuracy: 0.1497\n",
      "Epoch 33/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0032 - accuracy: 0.1497\n",
      "Epoch 34/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0030 - accuracy: 0.1498\n",
      "Epoch 35/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0029 - accuracy: 0.1498\n",
      "Epoch 36/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0027 - accuracy: 0.1498\n",
      "Epoch 37/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0029 - accuracy: 0.1498\n",
      "Epoch 38/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0027 - accuracy: 0.1498\n",
      "Epoch 39/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0025 - accuracy: 0.1498\n",
      "Epoch 40/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0025 - accuracy: 0.1499\n",
      "Epoch 41/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0023 - accuracy: 0.1499\n",
      "Epoch 42/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0023 - accuracy: 0.1499\n",
      "Epoch 43/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0021 - accuracy: 0.1499\n",
      "Epoch 44/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0021 - accuracy: 0.1499\n",
      "Epoch 45/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0021 - accuracy: 0.1499\n",
      "Epoch 46/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0020 - accuracy: 0.1500\n",
      "Epoch 47/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0020 - accuracy: 0.1500\n",
      "Epoch 48/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0019 - accuracy: 0.1500\n",
      "Epoch 49/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0019 - accuracy: 0.1500\n",
      "Epoch 50/50\n",
      "555/555 [==============================] - 33s 59ms/step - loss: 0.0019 - accuracy: 0.1500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7ae7ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 과정 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "79bab2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "          START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "      # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4841076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3fc41cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 영화볼래?\n",
      "출력 : 최신 영화가 좋을 것 같아요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'최신 영화가 좋을 것 같아요'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"영화볼래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c41759d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 자연어처리 공부를 해야지\n",
      "출력 : 하나씩 해보세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'하나씩 해보세요'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"자연어처리 공부를 해야지\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "60c8f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 점심 뭐 먹을까?\n",
      "출력 : 맛있는 거 드세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"점심 뭐 먹을까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4f5cfb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 심심해\n",
      "출력 : 친구들과 연락해보세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'친구들과 연락해보세요'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"심심해\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a62d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',  # 또는 'val_loss' (validation 데이터가 있을 경우)\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "DROPOUT = 0.3 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    max_length = MAX_LENGTH)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d522c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1, callbacks=[early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
